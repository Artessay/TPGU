{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "tf = tensorflow.compat.v1\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "tf.experimental.output_all_intermediates(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "valid_ratio = 0.2\n",
    "\n",
    "input_size = 202\n",
    "num_neurons = 160\n",
    "output_size = 158\n",
    "\n",
    "learning_rate = 0.001\n",
    "learning_rate_decay = 0.95\n",
    "\n",
    "max_epoch = 50\n",
    "batch_size = 1\n",
    "\n",
    "save_log_iter = 10\n",
    "display_iter = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集处理类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoilerDataSet(object):\n",
    "    \"\"\"\n",
    "    first run data_preparation.py to generate data.csv\n",
    "    prepare boiler training and validation dataset\n",
    "    simple version(small action dimension)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_steps, val_ratio=0.1):\n",
    "        self.num_steps = num_steps  # 历史步长\n",
    "        self.val_ratio = val_ratio  # 训练集与测试集比例\n",
    "        \n",
    "        # Read csv file\n",
    "        self.raw_data = pd.read_csv(\"./Simulator/data/sim_train.csv\", index_col='时间戳')\n",
    "\n",
    "        # sort csv file\n",
    "        cols = self.raw_data.columns.tolist()\n",
    "        # print(\"origin len: {0}\".format(len(cols)))\n",
    "        cols = (cols[51:52] + cols[53:59] + cols [60:61] + cols[62:63] + cols[150:152]   # external input \n",
    "            + cols[0:50] + cols[52:53] + cols[122:139]  # Coal Pulverizing state\n",
    "            + cols[50:51] + cols[59:60] + cols[61:62] + cols[63:101] + cols[112:114] + cols[118:122] + cols[139:145] + cols[146:149] + cols[152:158]    # Burning state\n",
    "            + cols[101:112] + cols[114:118] + cols[145:146] + cols[149:150] # Steam Circulation state\n",
    "            + cols[158:173] + cols[196:202] # Coal Pulverizing action\n",
    "            + cols[173:192]                 # Burning action\n",
    "            + cols[192:196])                # Steam Circulation action\n",
    "        print(\"ordered len: {0}\".format(len(cols)))\n",
    "        # self.raw_data = self.raw_data[cols]\n",
    "\n",
    "        # 划分训练集和测试集\n",
    "        self.train_X, self.train_y, self.valid_X, self.valid_y = self.prepare_data(self.raw_data)\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        # split into groups of num_steps\n",
    "\n",
    "        # 取出输入数据，学习num_steps步长的历史，iloc：通过行号获取行数据\n",
    "        X = np.array([data.iloc[i: i + self.num_steps].values\n",
    "                    for i in range(len(data) - self.num_steps)])\n",
    "\n",
    "        # 取出输出数据，预测第num_steps步的值训练，ix / loc 可以通过行号和行标签进行索引\n",
    "        # 这里只要对状态量进行预测即可，0-157列为 'A磨煤机电流':'大渣可燃物含量'\n",
    "        y = np.array([data.iloc[i+1: i + self.num_steps+1, 0:158].values\n",
    "                    for i in range(len(data) - self.num_steps)])\n",
    "\n",
    "        train_size = int(len(X) * (1.0 - self.val_ratio))\n",
    "        train_X, valid_X = X[:train_size], X[train_size:]\n",
    "        train_y, valid_y = y[:train_size], y[train_size:]\n",
    "        return train_X, train_y, valid_X, valid_y\n",
    "\n",
    "    def generate_one_epoch(self, data_X, data_y, batch_size):\n",
    "        num_batches = int(len(data_X)) // batch_size\n",
    "        # if batch_size * num_batches < len(self.train_X):\n",
    "        #     num_batches += 1\n",
    "\n",
    "        batch_indices = list(range(num_batches))\n",
    "        random.shuffle(batch_indices)\n",
    "        for j in batch_indices:\n",
    "            batch_X = data_X[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_y = data_y[j * batch_size: (j + 1) * batch_size]\n",
    "            yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordered len: 202\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "boiler_dataset = BoilerDataSet(num_steps=num_steps, val_ratio=valid_ratio)\n",
    "train_X, train_y = boiler_dataset.train_X, boiler_dataset.train_y\n",
    "valid_X, valid_y = boiler_dataset.valid_X, boiler_dataset.valid_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们的示例中，一共提供了20组数据，设置的时间步长为10.因此，分别有从[0:9]->[10], [1:10]->[11], ... , [9:18]->[19] 共十组（X，y）\\\\\n",
    "其中，我们训练集和测试集的比例为8：2，所以其中训练集有8组，测试集有2组。\\\\\n",
    "train_X (8, 10, 202) 分别为训练集组数、历史步长、数据维度 valid_y(2, 158) 分别为测试集组数和数据维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples: 8\n",
      "valid samples: 2\n"
     ]
    }
   ],
   "source": [
    "# 打印数据信息\n",
    "print('train samples: {0}'.format(len(train_X)))\n",
    "print('valid samples: {0}'.format(len(valid_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们的数据中，环境变量有11个，磨煤环节共有89个变量（68个状态和21个动作）、燃烧环节共有81个变量（62个状态和19个动作）、蒸汽循环环节共有21个变量（17个状态和4个动作）\n",
    "\n",
    "统计可知，一共有68+62+17=147个状态，21+19+4=44个动作，加上11个外界环境变量，共202个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=2022):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_18516\\1954548937.py:11: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  stacked_outputs = tf.layers.dense(stacked_rnn_outputs, output_size)\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, num_steps, input_size])\n",
    "y = tf.placeholder(tf.float32, [None, num_steps, output_size])\n",
    "\n",
    "basic_cell = tensorflow.keras.layers.SimpleRNNCell(units=num_neurons)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "# tensorflow.keras.layers.RNN(cell=basic_cell)\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, num_neurons])\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, output_size)\n",
    "# stacked_outputs = tensorflow.keras.layers.Dense(stacked_rnn_outputs, output_size)\n",
    "\n",
    "outputs = tf.reshape(stacked_outputs, [-1, num_steps, output_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"SimpleRNN\"\n",
    "logdir = './Simulator/logs/{}-{}-{}-{:.4f}/'.format(\n",
    "    model_name, num_neurons, num_steps, learning_rate)\n",
    "model_dir = logdir + 'saved_models/'\n",
    "\n",
    "from os import path, mkdir\n",
    "# 创建保存结果的文件夹\n",
    "if not path.exists('./Simulator/logs'):\n",
    "    mkdir('./Simulator/logs')\n",
    "if not path.exists(logdir):\n",
    "    mkdir(logdir)\n",
    "if not path.exists(model_dir):\n",
    "    mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)\n",
    "training_optimizer = optimizer.minimize(loss)\n",
    "\n",
    "loss_summary = tf.summary.scalar(\"loss_mse_train\", loss)\n",
    "learning_rate_summ = tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "# for var in tf.trainable_variables():\n",
    "#     tf.summary.histogram(var.name, var)\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------epoch 0-----------\n",
      "----------epoch 1-----------\n",
      "----------epoch 2-----------\n",
      "iter 20\tvalid_loss = 0.019768\tmodel saved\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_20.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_20.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_20.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "----------epoch 3-----------\n",
      "----------epoch 4-----------\n",
      "iter 40\tvalid_loss = 0.004362\tmodel saved\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_40.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_40.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_40.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "----------epoch 5-----------\n",
      "----------epoch 6-----------\n",
      "----------epoch 7-----------\n",
      "iter 60\tvalid_loss = 0.002182\tmodel saved\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_60.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_60.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_60.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "----------epoch 8-----------\n",
      "----------epoch 9-----------\n",
      "iter 80\tvalid_loss = 0.001710\tmodel saved\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_80.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_80.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_80.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "----------epoch 10-----------\n",
      "----------epoch 11-----------\n",
      "----------epoch 12-----------\n",
      "iter 100\tvalid_loss = 0.001566\tmodel saved\n",
      "WARNING:tensorflow:From d:\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1066: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_100.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_100.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_100.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "----------epoch 13-----------\n",
      "----------epoch 14-----------\n",
      "iter 120\tvalid_loss = 0.001328\tmodel saved\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_120.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_120.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_120.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "----------epoch 15-----------\n",
      "----------epoch 16-----------\n",
      "----------epoch 17-----------\n",
      "iter 140\tvalid_loss = 0.001191\tmodel saved\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_140.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_140.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_140.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "----------epoch 18-----------\n",
      "----------epoch 19-----------\n",
      "iter 160\tvalid_loss = 0.001041\tmodel saved\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_160.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_160.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_160.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "----------epoch 20-----------\n",
      "----------epoch 21-----------\n",
      "----------epoch 22-----------\n",
      "iter 180\tvalid_loss = 0.001185\t\n",
      "----------epoch 23-----------\n",
      "----------epoch 24-----------\n",
      "iter 200\tvalid_loss = 0.001352\t\n",
      "----------epoch 25-----------\n",
      "----------epoch 26-----------\n",
      "----------epoch 27-----------\n",
      "iter 220\tvalid_loss = 0.000920\tmodel saved\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_220.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_220.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_220.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "----------epoch 28-----------\n",
      "----------epoch 29-----------\n",
      "iter 240\tvalid_loss = 0.001076\t\n",
      "----------epoch 30-----------\n",
      "----------epoch 31-----------\n",
      "----------epoch 32-----------\n",
      "iter 260\tvalid_loss = 0.000981\t\n",
      "----------epoch 33-----------\n",
      "----------epoch 34-----------\n",
      "iter 280\tvalid_loss = 0.001194\t\n",
      "----------epoch 35-----------\n",
      "----------epoch 36-----------\n",
      "----------epoch 37-----------\n",
      "iter 300\tvalid_loss = 0.001189\t\n",
      "----------epoch 38-----------\n",
      "----------epoch 39-----------\n",
      "iter 320\tvalid_loss = 0.000950\t\n",
      "----------epoch 40-----------\n",
      "----------epoch 41-----------\n",
      "----------epoch 42-----------\n",
      "iter 340\tvalid_loss = 0.000921\t\n",
      "----------epoch 43-----------\n",
      "----------epoch 44-----------\n",
      "iter 360\tvalid_loss = 0.000881\tmodel saved\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_360.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_360.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\model_360.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:./Simulator/logs/SimpleRNN-160-10-0.0010/saved_models\\final_model.ckpt.meta\n",
      "INFO:tensorflow:1200\n",
      "----------epoch 45-----------\n",
      "----------epoch 46-----------\n",
      "----------epoch 47-----------\n",
      "iter 380\tvalid_loss = 0.000893\t\n",
      "----------epoch 48-----------\n",
      "----------epoch 49-----------\n",
      "iter 400\tvalid_loss = 0.000958\t\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())     # 初始化全局变量\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(logdir)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    iteration = 0           # 迭代数\n",
    "    valid_losses = [np.inf] # 损失值集合\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "        print('----------epoch {}-----------'.format(epoch))\n",
    "        \n",
    "        for batch_X, batch_y in boiler_dataset.generate_one_epoch(train_X, train_y, batch_size):\n",
    "            iteration += 1\n",
    "            sess.run(training_optimizer, feed_dict={X: batch_X, y: batch_y})\n",
    "\n",
    "            mse = loss.eval(feed_dict={X: batch_X, y: batch_y})\n",
    "            summary = sess.run(merged_summary, feed_dict={X: batch_X, y: batch_y})\n",
    "\n",
    "            if iteration % save_log_iter == 0:\n",
    "                summary_writer.add_summary(summary, iteration)\n",
    "            if iteration % display_iter == 0:\n",
    "                valid_loss = 0\n",
    "                for valid_batch_X, valid_batch_y in boiler_dataset.generate_one_epoch(valid_X, valid_y, batch_size):\n",
    "                    batch_mse = loss.eval(feed_dict={X: valid_batch_X, y: valid_batch_y})\n",
    "                    batch_loss = batch_mse      # @todo l2 loss\n",
    "                    valid_loss += batch_loss\n",
    "                num_batches = int(len(valid_X)) // batch_size\n",
    "                valid_loss /= num_batches       # 平均每个批次的损失\n",
    "                valid_losses.append(valid_loss)\n",
    "                valid_loss_sum = tf.Summary(\n",
    "                    value=[tf.Summary.Value(tag=\"valid_loss\", simple_value=valid_loss)])\n",
    "                summary_writer.add_summary(valid_loss_sum, iteration)\n",
    "\n",
    "                if valid_loss < min(valid_losses[:-1]):\n",
    "                    print('iter {}\\tvalid_loss = {:.6f}\\tmodel saved'.format(\n",
    "                        iteration, valid_loss))\n",
    "                    saver.save(sess, model_dir +\n",
    "                                'model_{}.ckpt'.format(iteration))\n",
    "                    saver.save(sess, model_dir + 'final_model.ckpt')\n",
    "                else:\n",
    "                    print('iter {}\\tvalid_loss = {:.6f}\\t'.format(\n",
    "                        iteration, valid_loss))\n",
    "        \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "301a17a29b57d3836b7901af1621afd6d2b1f2298b9c7949191147cf2fea93e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
