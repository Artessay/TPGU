{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoilerDataSet(object):\n",
    "    \n",
    "    def __init__(self, num_steps, val_ratio=0.1):\n",
    "        self.num_steps = num_steps  # time steps\n",
    "        self.val_ratio = val_ratio  # train test ratio\n",
    "        \n",
    "        # Read csv file\n",
    "        self.raw_data = pd.read_csv(\"./data/sim_train.csv\", index_col='时间戳')\n",
    "\n",
    "        # sort csv file\n",
    "        cols = self.raw_data.columns.tolist()\n",
    "        # print(\"origin len: {0}\".format(len(cols)))\n",
    "        cols = (cols[51:52] + cols[53:59] + cols [60:61] + cols[62:63] + cols[150:152]   # external input \n",
    "            + cols[0:50] + cols[52:53] + cols[122:139]  # Coal Pulverizing state\n",
    "            + cols[50:51] + cols[59:60] + cols[61:62] + cols[63:101] + cols[112:114] + cols[118:122] + cols[139:145] + cols[146:149] + cols[152:158]    # Burning state\n",
    "            + cols[101:112] + cols[114:118] + cols[145:146] + cols[149:150] # Steam Circulation state\n",
    "            + cols[158:173] + cols[196:202] # Coal Pulverizing action\n",
    "            + cols[173:192]                 # Burning action\n",
    "            + cols[192:196])                # Steam Circulation action\n",
    "        # print(\"ordered len: {0}\".format(len(cols)))\n",
    "        self.raw_data = self.raw_data[cols]\n",
    "\n",
    "        # divide train set and valid set\n",
    "        self.train_X, self.train_y, self.valid_X, self.valid_y = self.prepare_data(self.raw_data)\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        # split into groups of num_steps\n",
    "\n",
    "        # 取出输入数据，学习num_steps步长的历史，iloc：通过行号获取行数据\n",
    "        X = np.array([data.iloc[i: i + self.num_steps].values\n",
    "                    for i in range(len(data) - self.num_steps)])\n",
    "\n",
    "        # 取出输出数据，预测第num_steps步的值训练，ix / loc 可以通过行号和行标签进行索引\n",
    "        # 这里只要对状态量进行预测即可，0-157列为 'A磨煤机电流':'大渣可燃物含量'\n",
    "        y = np.array([data.iloc[i + self.num_steps, 158:203].values\n",
    "                    for i in range(len(data) - self.num_steps)])\n",
    "\n",
    "        train_size = int(len(X) * (1.0 - self.val_ratio))\n",
    "        train_X, valid_X = X[:train_size], X[train_size:]\n",
    "        train_y, valid_y = y[:train_size], y[train_size:]\n",
    "        return train_X, train_y, valid_X, valid_y\n",
    "\n",
    "    def generate_one_epoch(self, data_X, data_y, batch_size):\n",
    "        num_batches = int(len(data_X)) // batch_size\n",
    "        # if batch_size * num_batches < len(self.train_X):\n",
    "        #     num_batches += 1\n",
    "\n",
    "        batch_indices = list(range(num_batches))\n",
    "        random.shuffle(batch_indices)\n",
    "        for j in batch_indices:\n",
    "            batch_X = data_X[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_y = data_y[j * batch_size: (j + 1) * batch_size]\n",
    "            yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "valid_ratio = 0.2\n",
    "\n",
    "input_size = 202\n",
    "num_neurons = 160\n",
    "num_layers = 3\n",
    "output_size = 44\n",
    "\n",
    "learning_rate = 0.001\n",
    "learning_rate_decay = 0.95\n",
    "\n",
    "max_epoch = 50\n",
    "batch_size = 1\n",
    "\n",
    "save_log_iter = 10\n",
    "display_iter = 20\n",
    "\n",
    "tf.random.set_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 256)           470016    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " targets (Dense)             (None, 44)                5676      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 672,812\n",
      "Trainable params: 672,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def SimulatorRNNModel():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=[num_steps, input_size], name=\"inputs\"),\n",
    "        tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "        tf.keras.layers.LSTM(128),\n",
    "        tf.keras.layers.Dense(output_size, name=\"targets\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(), \n",
    "        optimizer=tf.keras.optimizers.Nadam(learning_rate=learning_rate), \n",
    "        metrics=['mean_absolute_error']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = SimulatorRNNModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(model, train_X, train_y, valid_X, valid_y, learning_rate, batch_size=1, epochs=500):\n",
    "    callback_list = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", \n",
    "            patience=50, \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='./logs/LSTM/saved_models/model-{epoch:02d}-{val_loss:.4f}.h5',\n",
    "            monitor=\"val_loss\",\n",
    "            verbose=1,\n",
    "            save_weights_only=True,\n",
    "            save_best_only=True,\n",
    "        ),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='./logs/')\n",
    "    ]   \n",
    "    \n",
    "    history = model.fit(\n",
    "        x=train_X, y=train_y,\n",
    "        epochs=epochs, \n",
    "        validation_data=(valid_X, valid_y),\n",
    "        callbacks=callback_list)\n",
    "    valid_loss, valid_mae = model.evaluate(x=valid_X, y=valid_y) # Returns the loss value & metrics values for the model in test mode\n",
    "    return valid_mae * 1e6  # valid mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "boiler_dataset = BoilerDataSet(num_steps=num_steps, val_ratio=valid_ratio)\n",
    "train_X, train_y = boiler_dataset.train_X, boiler_dataset.train_y\n",
    "valid_X, valid_y = boiler_dataset.valid_X, boiler_dataset.valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 44) (2, 44)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape, valid_y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1407 - mean_absolute_error: 0.2918\n",
      "Epoch 1: val_loss improved from inf to 0.06152, saving model to ./logs/LSTM/saved_models\\model-01-0.0615.h5\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1407 - mean_absolute_error: 0.2918 - val_loss: 0.0615 - val_mean_absolute_error: 0.1940\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0584 - mean_absolute_error: 0.1883\n",
      "Epoch 2: val_loss improved from 0.06152 to 0.04261, saving model to ./logs/LSTM/saved_models\\model-02-0.0426.h5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0584 - mean_absolute_error: 0.1883 - val_loss: 0.0426 - val_mean_absolute_error: 0.1447\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0408 - mean_absolute_error: 0.1398\n",
      "Epoch 3: val_loss improved from 0.04261 to 0.02872, saving model to ./logs/LSTM/saved_models\\model-03-0.0287.h5\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0408 - mean_absolute_error: 0.1398 - val_loss: 0.0287 - val_mean_absolute_error: 0.1386\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0275 - mean_absolute_error: 0.1339\n",
      "Epoch 4: val_loss improved from 0.02872 to 0.01825, saving model to ./logs/LSTM/saved_models\\model-04-0.0183.h5\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0275 - mean_absolute_error: 0.1339 - val_loss: 0.0183 - val_mean_absolute_error: 0.1062\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0175 - mean_absolute_error: 0.1036\n",
      "Epoch 5: val_loss improved from 0.01825 to 0.00937, saving model to ./logs/LSTM/saved_models\\model-05-0.0094.h5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0175 - mean_absolute_error: 0.1036 - val_loss: 0.0094 - val_mean_absolute_error: 0.0768\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - mean_absolute_error: 0.0724\n",
      "Epoch 6: val_loss improved from 0.00937 to 0.00525, saving model to ./logs/LSTM/saved_models\\model-06-0.0052.h5\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0086 - mean_absolute_error: 0.0724 - val_loss: 0.0052 - val_mean_absolute_error: 0.0601\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - mean_absolute_error: 0.0560\n",
      "Epoch 7: val_loss improved from 0.00525 to 0.00496, saving model to ./logs/LSTM/saved_models\\model-07-0.0050.h5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0044 - mean_absolute_error: 0.0560 - val_loss: 0.0050 - val_mean_absolute_error: 0.0574\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - mean_absolute_error: 0.0574\n",
      "Epoch 8: val_loss did not improve from 0.00496\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0047 - mean_absolute_error: 0.0574 - val_loss: 0.0058 - val_mean_absolute_error: 0.0606\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - mean_absolute_error: 0.0547\n",
      "Epoch 9: val_loss improved from 0.00496 to 0.00391, saving model to ./logs/LSTM/saved_models\\model-09-0.0039.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0045 - mean_absolute_error: 0.0547 - val_loss: 0.0039 - val_mean_absolute_error: 0.0483\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0035 - mean_absolute_error: 0.0473\n",
      "Epoch 10: val_loss improved from 0.00391 to 0.00353, saving model to ./logs/LSTM/saved_models\\model-10-0.0035.h5\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - mean_absolute_error: 0.0473 - val_loss: 0.0035 - val_mean_absolute_error: 0.0472\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0025 - mean_absolute_error: 0.0412\n",
      "Epoch 11: val_loss improved from 0.00353 to 0.00246, saving model to ./logs/LSTM/saved_models\\model-11-0.0025.h5\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0025 - mean_absolute_error: 0.0412 - val_loss: 0.0025 - val_mean_absolute_error: 0.0390\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0325\n",
      "Epoch 12: val_loss did not improve from 0.00246\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0017 - mean_absolute_error: 0.0325 - val_loss: 0.0025 - val_mean_absolute_error: 0.0399\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0016 - mean_absolute_error: 0.0335\n",
      "Epoch 13: val_loss did not improve from 0.00246\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0016 - mean_absolute_error: 0.0335 - val_loss: 0.0028 - val_mean_absolute_error: 0.0414\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0019 - mean_absolute_error: 0.0363\n",
      "Epoch 14: val_loss did not improve from 0.00246\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0019 - mean_absolute_error: 0.0363 - val_loss: 0.0035 - val_mean_absolute_error: 0.0491\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0437\n",
      "Epoch 15: val_loss did not improve from 0.00246\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - mean_absolute_error: 0.0437 - val_loss: 0.0041 - val_mean_absolute_error: 0.0501\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0476\n",
      "Epoch 16: val_loss did not improve from 0.00246\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0032 - mean_absolute_error: 0.0476 - val_loss: 0.0043 - val_mean_absolute_error: 0.0547\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0493\n",
      "Epoch 17: val_loss did not improve from 0.00246\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - mean_absolute_error: 0.0493 - val_loss: 0.0033 - val_mean_absolute_error: 0.0450\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0026 - mean_absolute_error: 0.0428\n",
      "Epoch 18: val_loss did not improve from 0.00246\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0026 - mean_absolute_error: 0.0428 - val_loss: 0.0029 - val_mean_absolute_error: 0.0423\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0352\n",
      "Epoch 19: val_loss improved from 0.00246 to 0.00173, saving model to ./logs/LSTM/saved_models\\model-19-0.0017.h5\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0018 - mean_absolute_error: 0.0352 - val_loss: 0.0017 - val_mean_absolute_error: 0.0310\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0266\n",
      "Epoch 20: val_loss did not improve from 0.00173\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0011 - mean_absolute_error: 0.0266 - val_loss: 0.0018 - val_mean_absolute_error: 0.0298\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3334e-04 - mean_absolute_error: 0.0208\n",
      "Epoch 21: val_loss improved from 0.00173 to 0.00120, saving model to ./logs/LSTM/saved_models\\model-21-0.0012.h5\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 7.3334e-04 - mean_absolute_error: 0.0208 - val_loss: 0.0012 - val_mean_absolute_error: 0.0239\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.4997e-04 - mean_absolute_error: 0.0175\n",
      "Epoch 22: val_loss did not improve from 0.00120\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.4997e-04 - mean_absolute_error: 0.0175 - val_loss: 0.0016 - val_mean_absolute_error: 0.0261\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7625e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 23: val_loss improved from 0.00120 to 0.00108, saving model to ./logs/LSTM/saved_models\\model-23-0.0011.h5\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4.7625e-04 - mean_absolute_error: 0.0156 - val_loss: 0.0011 - val_mean_absolute_error: 0.0221\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.5909e-04 - mean_absolute_error: 0.0150\n",
      "Epoch 24: val_loss did not improve from 0.00108\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 4.5909e-04 - mean_absolute_error: 0.0150 - val_loss: 0.0016 - val_mean_absolute_error: 0.0272\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7525e-04 - mean_absolute_error: 0.0156\n",
      "Epoch 25: val_loss improved from 0.00108 to 0.00107, saving model to ./logs/LSTM/saved_models\\model-25-0.0011.h5\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 4.7525e-04 - mean_absolute_error: 0.0156 - val_loss: 0.0011 - val_mean_absolute_error: 0.0230\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1947e-04 - mean_absolute_error: 0.0166\n",
      "Epoch 26: val_loss did not improve from 0.00107\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 5.1947e-04 - mean_absolute_error: 0.0166 - val_loss: 0.0019 - val_mean_absolute_error: 0.0305\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8427e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 27: val_loss did not improve from 0.00107\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 5.8427e-04 - mean_absolute_error: 0.0183 - val_loss: 0.0011 - val_mean_absolute_error: 0.0250\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.7351e-04 - mean_absolute_error: 0.0199\n",
      "Epoch 28: val_loss did not improve from 0.00107\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 6.7351e-04 - mean_absolute_error: 0.0199 - val_loss: 0.0022 - val_mean_absolute_error: 0.0344\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.7659e-04 - mean_absolute_error: 0.0218\n",
      "Epoch 29: val_loss did not improve from 0.00107\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.7659e-04 - mean_absolute_error: 0.0218 - val_loss: 0.0012 - val_mean_absolute_error: 0.0270\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.8826e-04 - mean_absolute_error: 0.0233\n",
      "Epoch 30: val_loss did not improve from 0.00107\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.8826e-04 - mean_absolute_error: 0.0233 - val_loss: 0.0025 - val_mean_absolute_error: 0.0378\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.8433e-04 - mean_absolute_error: 0.0247\n",
      "Epoch 31: val_loss did not improve from 0.00107\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.8433e-04 - mean_absolute_error: 0.0247 - val_loss: 0.0012 - val_mean_absolute_error: 0.0280\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0253\n",
      "Epoch 32: val_loss did not improve from 0.00107\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0010 - mean_absolute_error: 0.0253 - val_loss: 0.0027 - val_mean_absolute_error: 0.0387\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0011 - mean_absolute_error: 0.0252\n",
      "Epoch 33: val_loss did not improve from 0.00107\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - mean_absolute_error: 0.0252 - val_loss: 0.0012 - val_mean_absolute_error: 0.0271\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0246\n",
      "Epoch 34: val_loss did not improve from 0.00107\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0010 - mean_absolute_error: 0.0246 - val_loss: 0.0026 - val_mean_absolute_error: 0.0368\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6541e-04 - mean_absolute_error: 0.0234\n",
      "Epoch 35: val_loss improved from 0.00107 to 0.00101, saving model to ./logs/LSTM/saved_models\\model-35-0.0010.h5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 9.6541e-04 - mean_absolute_error: 0.0234 - val_loss: 0.0010 - val_mean_absolute_error: 0.0247\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.8533e-04 - mean_absolute_error: 0.0220\n",
      "Epoch 36: val_loss did not improve from 0.00101\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.8533e-04 - mean_absolute_error: 0.0220 - val_loss: 0.0025 - val_mean_absolute_error: 0.0341\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.2039e-04 - mean_absolute_error: 0.0209\n",
      "Epoch 37: val_loss improved from 0.00101 to 0.00091, saving model to ./logs/LSTM/saved_models\\model-37-0.0009.h5\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 8.2039e-04 - mean_absolute_error: 0.0209 - val_loss: 9.0646e-04 - val_mean_absolute_error: 0.0223\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.7090e-04 - mean_absolute_error: 0.0201\n",
      "Epoch 38: val_loss did not improve from 0.00091\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 7.7090e-04 - mean_absolute_error: 0.0201 - val_loss: 0.0024 - val_mean_absolute_error: 0.0328\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.6280e-04 - mean_absolute_error: 0.0201\n",
      "Epoch 39: val_loss improved from 0.00091 to 0.00088, saving model to ./logs/LSTM/saved_models\\model-39-0.0009.h5\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.6280e-04 - mean_absolute_error: 0.0201 - val_loss: 8.8311e-04 - val_mean_absolute_error: 0.0217\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.8623e-04 - mean_absolute_error: 0.0202\n",
      "Epoch 40: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.8623e-04 - mean_absolute_error: 0.0202 - val_loss: 0.0026 - val_mean_absolute_error: 0.0339\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7163e-04 - mean_absolute_error: 0.0217\n",
      "Epoch 41: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.7163e-04 - mean_absolute_error: 0.0217 - val_loss: 9.9315e-04 - val_mean_absolute_error: 0.0232\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0010 - mean_absolute_error: 0.0237\n",
      "Epoch 42: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0010 - mean_absolute_error: 0.0237 - val_loss: 0.0031 - val_mean_absolute_error: 0.0393\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0273\n",
      "Epoch 43: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0012 - mean_absolute_error: 0.0273 - val_loss: 0.0013 - val_mean_absolute_error: 0.0278\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0014 - mean_absolute_error: 0.0300\n",
      "Epoch 44: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0014 - mean_absolute_error: 0.0300 - val_loss: 0.0037 - val_mean_absolute_error: 0.0455\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0017 - mean_absolute_error: 0.0335\n",
      "Epoch 45: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0017 - mean_absolute_error: 0.0335 - val_loss: 0.0016 - val_mean_absolute_error: 0.0314\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0340\n",
      "Epoch 46: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - mean_absolute_error: 0.0340 - val_loss: 0.0037 - val_mean_absolute_error: 0.0464\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0018 - mean_absolute_error: 0.0340\n",
      "Epoch 47: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0018 - mean_absolute_error: 0.0340 - val_loss: 0.0015 - val_mean_absolute_error: 0.0299\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0306\n",
      "Epoch 48: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0015 - mean_absolute_error: 0.0306 - val_loss: 0.0029 - val_mean_absolute_error: 0.0398\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0273\n",
      "Epoch 49: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0012 - mean_absolute_error: 0.0273 - val_loss: 0.0013 - val_mean_absolute_error: 0.0256\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4088e-04 - mean_absolute_error: 0.0228\n",
      "Epoch 50: val_loss did not improve from 0.00088\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 9.4088e-04 - mean_absolute_error: 0.0228 - val_loss: 0.0020 - val_mean_absolute_error: 0.0319\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0020 - mean_absolute_error: 0.0319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31899.48946237564"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_and_evaluate(model, train_X, train_y, valid_X, valid_y, learning_rate, batch_size, max_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "301a17a29b57d3836b7901af1621afd6d2b1f2298b9c7949191147cf2fea93e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
