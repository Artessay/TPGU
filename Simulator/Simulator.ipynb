{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoilerDataSet(object):\n",
    "    \"\"\"\n",
    "    first run data_preparation.py to generate data.csv\n",
    "    prepare boiler training and validation dataset\n",
    "    simple version(small action dimension)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_steps, val_ratio=0.1):\n",
    "        self.num_steps = num_steps  # time steps\n",
    "        self.val_ratio = val_ratio  # train test ratio\n",
    "        \n",
    "        # Read csv file\n",
    "        self.raw_data = pd.read_csv(\"./data/sim_train.csv\", index_col='时间戳')\n",
    "\n",
    "        # sort csv file\n",
    "        cols = self.raw_data.columns.tolist()\n",
    "        # print(\"origin len: {0}\".format(len(cols)))\n",
    "        cols = (cols[51:52] + cols[53:59] + cols [60:61] + cols[62:63] + cols[150:152]   # external input \n",
    "            + cols[0:50] + cols[52:53] + cols[122:139]  # Coal Pulverizing state\n",
    "            + cols[50:51] + cols[59:60] + cols[61:62] + cols[63:101] + cols[112:114] + cols[118:122] + cols[139:145] + cols[146:149] + cols[152:158]    # Burning state\n",
    "            + cols[101:112] + cols[114:118] + cols[145:146] + cols[149:150] # Steam Circulation state\n",
    "            + cols[158:173] + cols[196:202] # Coal Pulverizing action\n",
    "            + cols[173:192]                 # Burning action\n",
    "            + cols[192:196])                # Steam Circulation action\n",
    "        # print(\"ordered len: {0}\".format(len(cols)))\n",
    "        self.raw_data = self.raw_data[cols]\n",
    "\n",
    "        # divide train set and valid set\n",
    "        self.train_X, self.train_y, self.valid_X, self.valid_y = self.prepare_data(self.raw_data)\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        # split into groups of num_steps\n",
    "\n",
    "        # 取出输入数据，学习num_steps步长的历史，iloc：通过行号获取行数据\n",
    "        X = np.array([data.iloc[i: i + self.num_steps].values\n",
    "                    for i in range(len(data) - self.num_steps)])\n",
    "\n",
    "        # 取出输出数据，预测第num_steps步的值训练，ix / loc 可以通过行号和行标签进行索引\n",
    "        # 这里只要对状态量进行预测即可，0-157列为 'A磨煤机电流':'大渣可燃物含量'\n",
    "        y = np.array([data.iloc[i + self.num_steps, 0:158].values\n",
    "                    for i in range(len(data) - self.num_steps)])\n",
    "\n",
    "        train_size = int(len(X) * (1.0 - self.val_ratio))\n",
    "        train_X, valid_X = X[:train_size], X[train_size:]\n",
    "        train_y, valid_y = y[:train_size], y[train_size:]\n",
    "        return train_X, train_y, valid_X, valid_y\n",
    "\n",
    "    def generate_one_epoch(self, data_X, data_y, batch_size):\n",
    "        num_batches = int(len(data_X)) // batch_size\n",
    "        # if batch_size * num_batches < len(self.train_X):\n",
    "        #     num_batches += 1\n",
    "\n",
    "        batch_indices = list(range(num_batches))\n",
    "        random.shuffle(batch_indices)\n",
    "        for j in batch_indices:\n",
    "            batch_X = data_X[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_y = data_y[j * batch_size: (j + 1) * batch_size]\n",
    "            yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class sim_config(object):\n",
    "num_steps = 10\n",
    "valid_ratio = 0.2\n",
    "\n",
    "input_size = 202\n",
    "num_neurons = 160\n",
    "num_layers = 3\n",
    "output_size = 158\n",
    "\n",
    "learning_rate = 0.001\n",
    "learning_rate_decay = 0.95\n",
    "\n",
    "max_epoch = 50\n",
    "batch_size = 1\n",
    "\n",
    "save_log_iter = 10\n",
    "display_iter = 20\n",
    "\n",
    "tf.random.set_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatorRNNCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.rnn_cell = tf.keras.layers.LSTMCell(units)\n",
    "                        # tf.keras.layers.SimpleRNNCell(units, # LSTMCell(units,\n",
    "                        #                                activation=None)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulatorRNNLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, cell, return_sequences=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.cell = cell\n",
    "        self.return_sequences = return_sequences\n",
    "\n",
    "    def get_initial_state(self, inputs):\n",
    "        try:\n",
    "            return self.cell.get_initial_state(inputs)\n",
    "        except AttributeError:\n",
    "            # fallback to zeros if self.cell has no get_initial_state() method\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            return [tf.zeros([batch_size, self.cell.state_size],\n",
    "                             dtype=inputs.dtype)]\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        states = self.get_initial_state(inputs)\n",
    "        shape = tf.shape(inputs)\n",
    "        batch_size = shape[0]\n",
    "        n_steps = shape[1]\n",
    "        sequences = tf.TensorArray(\n",
    "            inputs.dtype, size=(n_steps if self.return_sequences else 0))\n",
    "        outputs = tf.zeros(shape=[batch_size, self.cell.output_size],\n",
    "                           dtype=inputs.dtype)\n",
    "        for step in tf.range(n_steps):\n",
    "            outputs, states = self.cell(inputs[:, step], states)\n",
    "            if self.return_sequences:\n",
    "                sequences = sequences.write(step, outputs)\n",
    "\n",
    "        if self.return_sequences:\n",
    "            # stack the outputs into an array of shape\n",
    "            # [time steps, batch size, dims], then transpose it to shape\n",
    "            # [batch size, time steps, dims]\n",
    "            return tf.transpose(sequences.stack(), [1, 0, 2])\n",
    "        else:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 10, 256)           470016    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 158)               20382     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 687,518\n",
      "Trainable params: 687,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=[num_steps, input_size], name=\"inputs\"),\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    # tf.keras.layers.RNN(SimulatorRNNCell(128), input_shape=[None, num_steps, input_size]),\n",
    "    tf.keras.layers.Dense(158)\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(model, train_X, train_y, valid_X, valid_y, learning_rate, batch_size=1, epochs=500):\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=50, restore_best_weights=True)\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.MeanSquaredError(), \n",
    "        optimizer=tf.keras.optimizers.Nadam(learning_rate=learning_rate), \n",
    "        metrics=['mean_absolute_error'])\n",
    "    history = model.fit(\n",
    "        x=train_X, y=train_y,\n",
    "        epochs=epochs, \n",
    "        validation_data=(valid_X, valid_y),\n",
    "        callbacks=[early_stopping_callback])\n",
    "    valid_loss, valid_mae = model.evaluate(x=valid_X, y=valid_y) # Returns the loss value & metrics values for the model in test mode\n",
    "    return valid_mae * 1e6  # valid mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3000 - mean_absolute_error: 0.5043 - val_loss: 0.2073 - val_mean_absolute_error: 0.4024\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1955 - mean_absolute_error: 0.3909 - val_loss: 0.1501 - val_mean_absolute_error: 0.3226\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1401 - mean_absolute_error: 0.3113 - val_loss: 0.1105 - val_mean_absolute_error: 0.2680\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1026 - mean_absolute_error: 0.2575 - val_loss: 0.0836 - val_mean_absolute_error: 0.2273\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0766 - mean_absolute_error: 0.2162 - val_loss: 0.0619 - val_mean_absolute_error: 0.1883\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0569 - mean_absolute_error: 0.1803 - val_loss: 0.0458 - val_mean_absolute_error: 0.1651\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0409 - mean_absolute_error: 0.1552 - val_loss: 0.0320 - val_mean_absolute_error: 0.1272\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0282 - mean_absolute_error: 0.1204 - val_loss: 0.0216 - val_mean_absolute_error: 0.1058\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0184 - mean_absolute_error: 0.0980 - val_loss: 0.0144 - val_mean_absolute_error: 0.0853\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0119 - mean_absolute_error: 0.0806 - val_loss: 0.0099 - val_mean_absolute_error: 0.0664\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0075 - mean_absolute_error: 0.0599 - val_loss: 0.0064 - val_mean_absolute_error: 0.0548\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0044 - mean_absolute_error: 0.0492 - val_loss: 0.0045 - val_mean_absolute_error: 0.0443\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0027 - mean_absolute_error: 0.0374 - val_loss: 0.0035 - val_mean_absolute_error: 0.0380\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0018 - mean_absolute_error: 0.0330 - val_loss: 0.0028 - val_mean_absolute_error: 0.0361\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0015 - mean_absolute_error: 0.0301 - val_loss: 0.0031 - val_mean_absolute_error: 0.0343\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0014 - mean_absolute_error: 0.0297 - val_loss: 0.0027 - val_mean_absolute_error: 0.0363\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0015 - mean_absolute_error: 0.0309 - val_loss: 0.0032 - val_mean_absolute_error: 0.0354\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0015 - mean_absolute_error: 0.0308 - val_loss: 0.0026 - val_mean_absolute_error: 0.0356\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0015 - mean_absolute_error: 0.0306 - val_loss: 0.0031 - val_mean_absolute_error: 0.0345\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0014 - mean_absolute_error: 0.0293 - val_loss: 0.0025 - val_mean_absolute_error: 0.0332\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0012 - mean_absolute_error: 0.0276 - val_loss: 0.0027 - val_mean_absolute_error: 0.0316\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0011 - mean_absolute_error: 0.0261 - val_loss: 0.0023 - val_mean_absolute_error: 0.0306\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 9.1888e-04 - mean_absolute_error: 0.0235 - val_loss: 0.0024 - val_mean_absolute_error: 0.0283\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.2746e-04 - mean_absolute_error: 0.0225 - val_loss: 0.0023 - val_mean_absolute_error: 0.0286\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 7.2732e-04 - mean_absolute_error: 0.0204 - val_loss: 0.0022 - val_mean_absolute_error: 0.0263\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 6.7155e-04 - mean_absolute_error: 0.0199 - val_loss: 0.0022 - val_mean_absolute_error: 0.0271\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 6.1300e-04 - mean_absolute_error: 0.0183 - val_loss: 0.0021 - val_mean_absolute_error: 0.0253\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 5.7856e-04 - mean_absolute_error: 0.0182 - val_loss: 0.0022 - val_mean_absolute_error: 0.0263\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.4637e-04 - mean_absolute_error: 0.0170 - val_loss: 0.0020 - val_mean_absolute_error: 0.0248\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.2991e-04 - mean_absolute_error: 0.0172 - val_loss: 0.0022 - val_mean_absolute_error: 0.0264\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.2166e-04 - mean_absolute_error: 0.0164 - val_loss: 0.0021 - val_mean_absolute_error: 0.0249\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 5.3015e-04 - mean_absolute_error: 0.0169 - val_loss: 0.0023 - val_mean_absolute_error: 0.0274\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 5.6199e-04 - mean_absolute_error: 0.0172 - val_loss: 0.0022 - val_mean_absolute_error: 0.0264\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.2769e-04 - mean_absolute_error: 0.0187 - val_loss: 0.0025 - val_mean_absolute_error: 0.0303\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 7.5727e-04 - mean_absolute_error: 0.0207 - val_loss: 0.0025 - val_mean_absolute_error: 0.0305\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 9.3005e-04 - mean_absolute_error: 0.0235 - val_loss: 0.0029 - val_mean_absolute_error: 0.0352\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0012 - mean_absolute_error: 0.0268 - val_loss: 0.0029 - val_mean_absolute_error: 0.0350\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0013 - mean_absolute_error: 0.0287 - val_loss: 0.0032 - val_mean_absolute_error: 0.0376\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - mean_absolute_error: 0.0304 - val_loss: 0.0030 - val_mean_absolute_error: 0.0361\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - mean_absolute_error: 0.0295 - val_loss: 0.0029 - val_mean_absolute_error: 0.0352\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - mean_absolute_error: 0.0284 - val_loss: 0.0027 - val_mean_absolute_error: 0.0335\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0010 - mean_absolute_error: 0.0258 - val_loss: 0.0025 - val_mean_absolute_error: 0.0306\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.8206e-04 - mean_absolute_error: 0.0237 - val_loss: 0.0024 - val_mean_absolute_error: 0.0304\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.4330e-04 - mean_absolute_error: 0.0215 - val_loss: 0.0022 - val_mean_absolute_error: 0.0271\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 6.4413e-04 - mean_absolute_error: 0.0199 - val_loss: 0.0023 - val_mean_absolute_error: 0.0281\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 5.7493e-04 - mean_absolute_error: 0.0183 - val_loss: 0.0021 - val_mean_absolute_error: 0.0249\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.2704e-04 - mean_absolute_error: 0.0175 - val_loss: 0.0023 - val_mean_absolute_error: 0.0271\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 5.0056e-04 - mean_absolute_error: 0.0166 - val_loss: 0.0020 - val_mean_absolute_error: 0.0239\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.8527e-04 - mean_absolute_error: 0.0165 - val_loss: 0.0023 - val_mean_absolute_error: 0.0271\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 4.8873e-04 - mean_absolute_error: 0.0163 - val_loss: 0.0019 - val_mean_absolute_error: 0.0241\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0019 - mean_absolute_error: 0.0241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24110.43643951416"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "boiler_dataset = BoilerDataSet(num_steps=num_steps, val_ratio=valid_ratio)\n",
    "train_X, train_y = boiler_dataset.train_X, boiler_dataset.train_y\n",
    "valid_X, valid_y = boiler_dataset.valid_X, boiler_dataset.valid_y\n",
    "\n",
    "fit_and_evaluate(model, train_X, train_y, valid_X, valid_y, learning_rate, batch_size, max_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "301a17a29b57d3836b7901af1621afd6d2b1f2298b9c7949191147cf2fea93e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
